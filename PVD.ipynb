{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jeff\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns removed due to multicollinearity: []\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      " Complains Of Pain       0.68      0.95      0.79       554\n",
      "             Fatal       0.00      0.00      0.00        11\n",
      "    Incapacitating       0.25      0.02      0.03        62\n",
      "         No Injury       0.07      0.01      0.02        85\n",
      "Non-Incapacitating       0.10      0.02      0.03       104\n",
      "           Unknown       0.00      0.00      0.00         3\n",
      "\n",
      "          accuracy                           0.65       819\n",
      "         macro avg       0.18      0.17      0.15       819\n",
      "      weighted avg       0.50      0.65      0.54       819\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jeff\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Jeff\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Jeff\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Jeff\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "###MULTINOMIAL LOGISTIC REGRESSION\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Load the dataset\n",
    "pvd = pd.read_csv(\"C:/Users/Jeff/Desktop/pvd.tsv\", sep='\\t')\n",
    "\n",
    "columns_to_keep = [\n",
    "    'collision_type', 'street_or_highway', 'nearest_intersection', 'type_of_roadway',\n",
    "    'road_surface_condition', 'light_condition', 'weather_condition', 'manner_of_impact',\n",
    "    'hit_and_run', 'traffic_control', 'most_serious_injury',\n",
    "    'count_pedestrian', 'count_bicycle', 'scooter', 'wheel_chair'\n",
    "]\n",
    "\n",
    "pvd2 = pvd[columns_to_keep]\n",
    "\n",
    "# Fill NA with zeros\n",
    "cols = [\"count_pedestrian\", \"count_bicycle\"]\n",
    "pvd2[cols] = pvd2[cols].fillna(0)\n",
    "\n",
    "# Convert columns to factors\n",
    "col_fac = [\"collision_type\", \"street_or_highway\", 'nearest_intersection', 'type_of_roadway',\n",
    "           \"road_surface_condition\", \"light_condition\", \"weather_condition\", \"manner_of_impact\", \"hit_and_run\",\n",
    "           \"traffic_control\", \"most_serious_injury\"]\n",
    "pvd2[col_fac] = pvd2[col_fac].astype('category')\n",
    "\n",
    "# Drop rows with NA values\n",
    "pvd3 = pvd2.dropna()\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "X_numeric = pvd3.select_dtypes(include=['number'])\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X_numeric.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_numeric.values, i) for i in range(X_numeric.shape[1])]\n",
    "\n",
    "# Remove columns with high VIF (e.g., VIF > 10 is often considered high)\n",
    "high_vif_cols = vif_data[vif_data[\"VIF\"] > 10][\"feature\"].tolist()\n",
    "X_filtered = pvd3.drop(columns=high_vif_cols)\n",
    "\n",
    "# Print the columns removed\n",
    "print(\"Columns removed due to multicollinearity:\", high_vif_cols)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X = X_filtered.drop(columns=['most_serious_injury'])\n",
    "y = X_filtered['most_serious_injury']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define preprocessing steps\n",
    "numeric_features = ['count_pedestrian', 'count_bicycle']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['collision_type', 'street_or_highway', 'nearest_intersection', 'type_of_roadway',\n",
    "                        'road_surface_condition', 'light_condition', 'weather_condition', 'manner_of_impact',\n",
    "                        'hit_and_run', 'traffic_control']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Create a pipeline with preprocessing and logistic regression\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression(multi_class='multinomial', solver='lbfgs'))])\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jeff\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'statsmodels' has no attribute 'add_constant'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Calculate the standard errors\u001b[39;00m\n\u001b[0;32m     13\u001b[0m X_train_transformed \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(X_train)\n\u001b[1;32m---> 14\u001b[0m logit_model \u001b[38;5;241m=\u001b[39m Logit(y_train, \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_constant\u001b[49m(X_train_transformed))\n\u001b[0;32m     15\u001b[0m result \u001b[38;5;241m=\u001b[39m logit_model\u001b[38;5;241m.\u001b[39mfit(disp\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     16\u001b[0m standard_errors \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mbse\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'statsmodels' has no attribute 'add_constant'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the coefficients\n",
    "coefficients = clf.named_steps['classifier'].coef_[0]\n",
    "intercept = clf.named_steps['classifier'].intercept_\n",
    "\n",
    "# Calculate the standard errors\n",
    "X_train_transformed = clf.named_steps['preprocessor'].transform(X_train)\n",
    "logit_model = Logit(y_train, sm.add_constant(X_train_transformed))\n",
    "result = logit_model.fit(disp=0)\n",
    "standard_errors = result.bse\n",
    "\n",
    "# Calculate the z-scores\n",
    "z_scores = coefficients / standard_errors\n",
    "\n",
    "# Calculate the p-values\n",
    "p_values = [2 * (1 - stats.norm.cdf(np.abs(z))) for z in z_scores]\n",
    "\n",
    "# Print the coefficients and p-values\n",
    "for i, col in enumerate(X_train.columns):\n",
    "    print(f\"Feature: {col}\")\n",
    "    print(f\"Coefficient: {coefficients[i]}\")\n",
    "    print(f\"Standard Error: {standard_errors[i]}\")\n",
    "    print(f\"Z-score: {z_scores[i]}\")\n",
    "    print(f\"P-value: {p_values[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation Importance:\n",
      "nearest_intersection: -0.009 +/- 0.003\n",
      "street_or_highway: -0.007 +/- 0.005\n",
      "count_pedestrian: -0.005 +/- 0.002\n",
      "manner_of_impact: -0.003 +/- 0.002\n",
      "road_surface_condition: -0.003 +/- 0.002\n",
      "hit_and_run: -0.002 +/- 0.001\n",
      "traffic_control: -0.002 +/- 0.002\n",
      "light_condition: -0.001 +/- 0.002\n",
      "weather_condition: -0.001 +/- 0.002\n",
      "type_of_roadway: -0.000 +/- 0.003\n",
      "scooter: 0.000 +/- 0.000\n",
      "wheel_chair: 0.000 +/- 0.000\n",
      "collision_type: 0.026 +/- 0.003\n",
      "count_bicycle: 0.041 +/- 0.008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import RFE\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Permutation Importance\n",
    "perm_importance = permutation_importance(clf, X_test, y_test)\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "\n",
    "# Print permutation importance\n",
    "print(\"Permutation Importance:\")\n",
    "for i in sorted_idx:\n",
    "    print(f\"{X.columns[i]}: {perm_importance.importances_mean[i]:.3f} +/- {perm_importance.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients for class 'Complains Of Pain':\n",
      "  collision_type: 0.1390490093182854\n",
      "  street_or_highway: 0.5246577150583364\n",
      "  nearest_intersection: 0.08264535983473806\n",
      "  type_of_roadway: -0.42378862047914884\n",
      "  road_surface_condition: 0.7417065871791382\n",
      "  light_condition: 0.207589406141592\n",
      "  weather_condition: 0.30700837997867\n",
      "  manner_of_impact: -0.3122001036857691\n",
      "  hit_and_run: 0.19296802512899497\n",
      "  traffic_control: -0.1641816749655645\n",
      "  count_pedestrian: -0.4055722758025654\n",
      "  count_bicycle: -0.4236078813102915\n",
      "  scooter: 0.21835605667218735\n",
      "  wheel_chair: 0.1612166566749147\n",
      "Intercept for class 'Complains Of Pain': 1.7612340892608727\n",
      "\n",
      "Coefficients for class 'Fatal':\n",
      "  collision_type: 0.37892978603463895\n",
      "  street_or_highway: -0.5687181845870778\n",
      "  nearest_intersection: -0.5735405968924957\n",
      "  type_of_roadway: -0.15097418150407116\n",
      "  road_surface_condition: 0.20472156495836344\n",
      "  light_condition: -0.000355654396076773\n",
      "  weather_condition: -0.009579533290369216\n",
      "  manner_of_impact: -0.012138039306729902\n",
      "  hit_and_run: -0.00471474421544793\n",
      "  traffic_control: -0.00606961146400407\n",
      "  count_pedestrian: -0.005648873504495429\n",
      "  count_bicycle: -0.0003028457642118912\n",
      "  scooter: -0.004383665117802142\n",
      "  wheel_chair: -0.008353658006164232\n",
      "Intercept for class 'Fatal': -2.1432448539315665\n",
      "\n",
      "Coefficients for class 'Incapacitating':\n",
      "  collision_type: 0.33254688808451816\n",
      "  street_or_highway: 0.715901927455767\n",
      "  nearest_intersection: -0.38658439085713203\n",
      "  type_of_roadway: 0.09049277385008651\n",
      "  road_surface_condition: 0.5151338162347054\n",
      "  light_condition: -0.03280904674607594\n",
      "  weather_condition: -0.12421884378455939\n",
      "  manner_of_impact: 0.49852738790951645\n",
      "  hit_and_run: -0.04126842853486689\n",
      "  traffic_control: -0.08687758679379481\n",
      "  count_pedestrian: -0.07185221860060477\n",
      "  count_bicycle: 0.7507143047179894\n",
      "  scooter: -0.07778254027036188\n",
      "  wheel_chair: -0.050788463607993085\n",
      "Intercept for class 'Incapacitating': 0.8244713121662238\n",
      "\n",
      "Coefficients for class 'No Injury':\n",
      "  collision_type: -0.09399752350857095\n",
      "  street_or_highway: -0.19309690208081226\n",
      "  nearest_intersection: 0.636509176045717\n",
      "  type_of_roadway: 0.15727853334580646\n",
      "  road_surface_condition: -0.6078503452032972\n",
      "  light_condition: -0.09457052016375236\n",
      "  weather_condition: -0.03888832638380488\n",
      "  manner_of_impact: -0.02304931004320398\n",
      "  hit_and_run: -0.04634050103353386\n",
      "  traffic_control: 0.4553976836037975\n",
      "  count_pedestrian: -0.07574228170547483\n",
      "  count_bicycle: -0.22016446833209355\n",
      "  scooter: -0.04099370316032547\n",
      "  wheel_chair: -0.02656541181762025\n",
      "Intercept for class 'No Injury': 0.7097112958684987\n",
      "\n",
      "Coefficients for class 'Non-Incapacitating':\n",
      "  collision_type: 0.07680327524255144\n",
      "  street_or_highway: 0.33901167186988224\n",
      "  nearest_intersection: -0.03937215817490459\n",
      "  type_of_roadway: 0.17601519863081497\n",
      "  road_surface_condition: -0.03654290027809842\n",
      "  light_condition: -0.07916112189591124\n",
      "  weather_condition: -0.13154461064632283\n",
      "  manner_of_impact: -0.1499201111733621\n",
      "  hit_and_run: -0.09861048287196583\n",
      "  traffic_control: -0.19471959475571957\n",
      "  count_pedestrian: 0.5612920622606037\n",
      "  count_bicycle: -0.10277398851962748\n",
      "  scooter: -0.0942917321282611\n",
      "  wheel_chair: -0.07427804592760501\n",
      "Intercept for class 'Non-Incapacitating': 0.3678551822791682\n",
      "\n",
      "Coefficients for class 'Unknown':\n",
      "  collision_type: -0.8333314351714172\n",
      "  street_or_highway: -0.8177562277161011\n",
      "  nearest_intersection: 0.28034261004407895\n",
      "  type_of_roadway: 0.1509762961565078\n",
      "  road_surface_condition: -0.8171687228908165\n",
      "  light_condition: -0.0006930629397759321\n",
      "  weather_condition: -0.002777065873612178\n",
      "  manner_of_impact: -0.0012198237004520042\n",
      "  hit_and_run: -0.002033868473180359\n",
      "  traffic_control: -0.0035492156247160346\n",
      "  count_pedestrian: -0.0024764126474607563\n",
      "  count_bicycle: -0.003865120791761725\n",
      "  scooter: -0.0009044159954366091\n",
      "  wheel_chair: -0.0012310773155332028\n",
      "Intercept for class 'Unknown': -1.5200270256431636\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the coefficients and intercepts from the trained logistic regression model\n",
    "coefficients = clf.named_steps['classifier'].coef_\n",
    "intercept = clf.named_steps['classifier'].intercept_\n",
    "\n",
    "# Print the coefficients for each feature and class\n",
    "for i, class_name in enumerate(clf.named_steps['classifier'].classes_):\n",
    "    print(f\"Coefficients for class '{class_name}':\")\n",
    "    for j, feature_name in enumerate(X_train.columns):\n",
    "        print(f\"  {feature_name}: {coefficients[i][j]}\")\n",
    "    print(f\"Intercept for class '{class_name}': {intercept[i]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jeff\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns removed due to multicollinearity: []\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      " Complains Of Pain       0.67      0.97      0.79       554\n",
      "             Fatal       0.00      0.00      0.00        11\n",
      "    Incapacitating       0.25      0.02      0.03        62\n",
      "         No Injury       0.09      0.01      0.02        85\n",
      "Non-Incapacitating       0.00      0.00      0.00       104\n",
      "           Unknown       0.00      0.00      0.00         3\n",
      "\n",
      "          accuracy                           0.66       819\n",
      "         macro avg       0.17      0.17      0.14       819\n",
      "      weighted avg       0.48      0.66      0.54       819\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jeff\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Jeff\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Jeff\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "###RANDOM FOREST\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Load the dataset\n",
    "pvd = pd.read_csv(\"C:/Users/Jeff/Desktop/pvd.tsv\", sep='\\t')\n",
    "\n",
    "columns_to_keep = [\n",
    "    'collision_type', 'street_or_highway', 'nearest_intersection', 'type_of_roadway',\n",
    "    'road_surface_condition', 'light_condition', 'weather_condition', 'manner_of_impact',\n",
    "    'hit_and_run', 'traffic_control', 'most_serious_injury',\n",
    "    'count_pedestrian', 'count_bicycle', 'scooter', 'wheel_chair'\n",
    "]\n",
    "\n",
    "pvd2 = pvd[columns_to_keep]\n",
    "\n",
    "# Fill NA with zeros\n",
    "cols = [\"count_pedestrian\", \"count_bicycle\"]\n",
    "pvd2[cols] = pvd2[cols].fillna(0)\n",
    "\n",
    "# Convert columns to factors\n",
    "col_fac = [\"collision_type\", \"street_or_highway\", 'nearest_intersection', 'type_of_roadway',\n",
    "           \"road_surface_condition\", \"light_condition\", \"weather_condition\", \"manner_of_impact\", \"hit_and_run\",\n",
    "           \"traffic_control\", \"most_serious_injury\"]\n",
    "pvd2[col_fac] = pvd2[col_fac].astype('category')\n",
    "\n",
    "# Drop rows with NA values\n",
    "pvd3 = pvd2.dropna()\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "X_numeric = pvd3.select_dtypes(include=['number'])\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X_numeric.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_numeric.values, i) for i in range(X_numeric.shape[1])]\n",
    "\n",
    "# Remove columns with high VIF (e.g., VIF > 10 is often considered high)\n",
    "high_vif_cols = vif_data[vif_data[\"VIF\"] > 10][\"feature\"].tolist()\n",
    "X_filtered = pvd3.drop(columns=high_vif_cols)\n",
    "\n",
    "# Print the columns removed\n",
    "print(\"Columns removed due to multicollinearity:\", high_vif_cols)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X = X_filtered.drop(columns=['most_serious_injury'])\n",
    "y = X_filtered['most_serious_injury']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define preprocessing steps\n",
    "numeric_features = ['count_pedestrian', 'count_bicycle']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['collision_type', 'street_or_highway', 'nearest_intersection', 'type_of_roadway',\n",
    "                        'road_surface_condition', 'light_condition', 'weather_condition', 'manner_of_impact',\n",
    "                        'hit_and_run', 'traffic_control']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Create a pipeline with preprocessing and random forest classifier\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))])\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[537   0   3   8   6   0]\n",
      " [ 10   0   0   1   0   0]\n",
      " [ 60   0   1   1   0   0]\n",
      " [ 83   0   0   1   1   0]\n",
      " [104   0   0   0   0   0]\n",
      " [  3   0   0   0   0   0]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(cm)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Get feature importances from the trained random forest model\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m feature_importances \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamed_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclassifier\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_importances_\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Create a dictionary to store feature importance scores for each response category\u001b[39;00m\n\u001b[0;32m     12\u001b[0m feature_importance_per_response \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Get feature importances from the trained random forest model\n",
    "feature_importances = clf.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Create a dictionary to store feature importance scores for each response category\n",
    "feature_importance_per_response = {}\n",
    "\n",
    "# Associate features with response categories\n",
    "for i, response_category in enumerate(clf.named_steps['classifier'].classes_):\n",
    "    feature_importance_per_response[response_category] = feature_importances[i]\n",
    "\n",
    "# Sort the dictionary by importance scores (optional)\n",
    "sorted_feature_importance_per_response = dict(sorted(feature_importance_per_response.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "# Print or visualize the results\n",
    "for response_category, importance_score in sorted_feature_importance_per_response.items():\n",
    "    print(f\"Response Category: {response_category}, Feature Importance: {importance_score}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation Importance:\n",
      "nearest_intersection: -0.013 +/- 0.002\n",
      "street_or_highway: -0.009 +/- 0.002\n",
      "traffic_control: -0.007 +/- 0.002\n",
      "manner_of_impact: -0.005 +/- 0.002\n",
      "hit_and_run: -0.005 +/- 0.003\n",
      "weather_condition: -0.004 +/- 0.001\n",
      "type_of_roadway: -0.004 +/- 0.001\n",
      "light_condition: -0.001 +/- 0.002\n",
      "count_pedestrian: -0.001 +/- 0.003\n",
      "road_surface_condition: -0.000 +/- 0.002\n",
      "count_bicycle: 0.000 +/- 0.004\n",
      "scooter: 0.000 +/- 0.000\n",
      "wheel_chair: 0.000 +/- 0.000\n",
      "collision_type: 0.013 +/- 0.005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.feature_selection import RFE\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Permutation Importance\n",
    "perm_importance = permutation_importance(clf, X_test, y_test)\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "\n",
    "# Print permutation importance\n",
    "print(\"Permutation Importance:\")\n",
    "for i in sorted_idx:\n",
    "    print(f\"{X.columns[i]}: {perm_importance.importances_mean[i]:.3f} +/- {perm_importance.importances_std[i]:.3f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
